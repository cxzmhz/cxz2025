## 员工平台

https://dev.azure.com/xiaobingai/AICreation/_git/AvatarFrontEnd?path=/private/AIDigitalEmployees

https://aibeings-vip-int.xiaoice.com/

## 渠道平台

https://dev.azure.com/xiaobingai/AICreation/_git/UserExperience?path=/private/ChannelOperation

https://aibeing-enterprise-center-int.xiaoice.com/

## 运营平台

https://dev.azure.com/xiaobingai/AICreation/_git/AvatarFrontEnd?path=/private/VHOperationPlatform

https://operation-int.xiaoice.com

## 账号中心

https://dev.azure.com/xiaobingai/AICreation/_git/AvatarFrontEnd?path=/private/PublicAccount

https://aibeing-account-int.xiaoice.com/

## AgentX

https://dev.azure.com/xiaobingai/AICreation/_git/AvatarFrontEnd?path=/private/AiAgent

https://aibeings-agent-int.xiaoice.com/

## AgentXFlow

https://dev.azure.com/xiaobingai/AICreation/_git/AvatarFrontEnd?path=/private/AiAgentWorkflow

https://aibeings-agent-int.xiaoice.com/workflow-builder/app/37d363ec-cdb2-4f62-b412-736133c0ea89/workflow

## 发版流程

1. master 切 feature 分支开发
2. 开发完成，推代码，pr 到 int 分支提测，如果有冲突，本地拉临时分支 fixconflict，fixconflict->int（分支名： deploy/aidigitalemployees-front/int），合完删除临时分支，如果冲突较多，且 int 暂无其他人提测，可以才用删除 int 分支，从 master 重新切一个干净的 int 分支，然后再 feature->int
3. int 测试完成，feature->master，需要指定 reviewer
4. master=>prod（分支名： deploy/aidigitalemployees-front/prod），需要指定 审核人，然后点击右上角的 auto complete，这个时候是部署到 staging 环境（在部署的过程中有一步需要手动点击 review 确认通过）
5. staging 环境让产品复测一遍，没问题再切 prod 环境（需要在上线群里找郑东帮忙切换），此时 staging 会回退到上一个版本，如果 prod 出现无法定位的问题，可以找运维帮忙回滚
6. 切记，pipeline 发版最好不要过夜切 prod，staging 禁止两个 pipeline 同时进行
7. 私有化的包授权流程参考 https://dev.azure.com/xiaobingai/AICreation/_artifacts/feed/npm-registry/connect mac 可以使用文档里的 other 方式
8. 注意始终不要将部署分支 pr 到开发分支
9. 分支删除只能找创建分支的人或者高权限的人或者运维帮忙删除
10. pr 进 master 使用 squash commit
11. pr 进 int 使用 merge commit
12. pr 规定需要至少两人 approve

## 私有包地址

1. 本地 https://pkgs.dev.azure.com/aibeings/_packaging/xiaoice-npm/npm/registry/
2. 线上 https://dev.azure.com/aibeings/aibeings/_artifacts/feed/xiaoice-npm@Local/connect

## 注意事项

1. ChannelOperation 用 yarn
2. Aiagent 不用管 .npmrc 用 18 去跑
3. VHOPERATIONPLATFORM 也是一样
4. AIDigitalEmployees 用 yarn 管理，用 node16 去跑

- .eslintrc.js 如果配置了正确的 tsconfig.json 路径，但还是提示找不到，可以在 vscode 的设置里面添加这项设置

```json
"eslint.workingDirectories": [
  { "mode": "auto" }
]
```

- tsconfig.json 配置里面的 project 要不要改成这种绝对路径的方式

```js
parserOptions: {
  project: require('path').join(__dirname, './tsconfig.json')
},
```

- .npmrc 里面的 registry 要不要改成`@ice-components:registry`的方式来限定 scope

- 记得连接 vpn

- vsts-npm-auth
  `vsts-npm-auth -config .npmrc`

## 私有仓库授权

### windows

1. 先将.npmrc 里面的 registry 改成`https://pkgs.dev.azure.com/aibeings/_packaging/xiaoice-npm/npm/registry/`

2. 将 yarn.lock 或 package-lock.json 里面的使用旧的 registry 的包全部替换成上面这个新的 registry

3. 控制台切换到当前项目目录，执行`vsts-npm-auth -config .npmrc`

4. 运行`yarn install`或`npm install`安装依赖

### mac

1. 将下面所有的代码复制到项目的.npmrc 文件中

```bash
registry=https://pkgs.dev.azure.com/aibeings/_packaging/xiaoice-npm/npm/registry/
always-auth=true
; begin auth token
//pkgs.dev.azure.com/aibeings/_packaging/xiaoice-npm/npm/registry/:username=aibeings
//pkgs.dev.azure.com/aibeings/_packaging/xiaoice-npm/npm/registry/:_password=N2RBVGp6U2ZHVUQ4Njk2bXpCSE84clhxZWxEamtvZWRFakpTUnN1bTJRcjFKcHJUOHA0dkpRUUo5OUJHQUNBQUFBQVdiRWJoQUFBU0FaRE8zTlhG
//pkgs.dev.azure.com/aibeings/_packaging/xiaoice-npm/npm/registry/:email=npm requires email to be set but doesn't use the value
//pkgs.dev.azure.com/aibeings/_packaging/xiaoice-npm/npm/:username=aibeings
//pkgs.dev.azure.com/aibeings/_packaging/xiaoice-npm/npm/:_password=N2RBVGp6U2ZHVUQ4Njk2bXpCSE84clhxZWxEamtvZWRFakpTUnN1bTJRcjFKcHJUOHA0dkpRUUo5OUJHQUNBQUFBQVdiRWJoQUFBU0FaRE8zTlhG
//pkgs.dev.azure.com/aibeings/_packaging/xiaoice-npm/npm/:email=npm requires email to be set but doesn't use the value
; end auth token
```

2. 将项目中如果有旧的 registry 的包全部替换成上面这个新的 registry
   旧： `https://pkgs.dev.azure.com/xiaobingai/AICreation/_packaging/npm-registry/npm/registry/`
   新： `https://pkgs.dev.azure.com/aibeings/_packaging/xiaoice-npm/npm/registry/`

# 熟悉项目相关信息

## 代码问题待处理

1. AvatarFrontEnd 本地开发环境打包慢的问题
2. ASRsdk 权益的扣减是在前端处理
3. 交互名片或交互 sdk 的逻辑是在无响应 5 分钟后后端才会断连，可不可以使用 fetch keep-alive 的方式在页面关闭之前发送请求去断开连接？（提升用户的体验，也避免后端一直监听接口，浪费服务器资源）
4. 每次开发手动要做的事情太多，心智负担太重，后续一步步慢慢优化自动化处理，如：交互 sdk 的平台预览模块代码，直接拷贝了 RTC-sdk 的代码过来自己维护一份，需要通过回溯查清楚为什么要这么处理
5. 文档里面要对更新点明确到具体的属性说明上面，重点表示出来，便于快速查看，如：xxx 属性在 1.0.7 版本中弃用
6. 文档要保留记录
7. 紧急的更新可以通过加小版本的方式更新，不要是用旧版本号，如：当前是 1.0.7，紧急更新一个版本后，需要改成 1.0.7.1
8. ASRsdk 的打包方法需要优化下，只保留最后的 merge.js 即可，其他的删掉
9. sdk 的 ts 类型校验是否有问题
10. 小程序维护一个关于页面，微信有暴露一个变量，每次上传的时候微信会根据我们填版本号去更新这个变量的值，我们就可以直接拿这个变量的值去显示版本号了
11. 小程序的体验环境和生产环境应该是 2 个不同的小程序，也是 2 个不同的小程序码，为什么会出现同个码有时候扫出来是体验版，有时候扫出来是生产版呢？
12. 小程序可以做个开发者的配置，随时切换 int，staging，production 配置
13. 后续引入 eslint，prettier
14. ts 类型治理
15. oss 上传自动化处理：打包上传当前 sdk，拉取其他 sdk 打一个压缩包上传
16. 每次发布的时候发 2 个包，一个是照常更新版本号的（1.0.7），一个是固定名叫 latest 的
17. 公共组件有些未做好封装，甚至有一模一样的组件，导致代码重复，如：`src\pages\home\project\components\InteractiveCardList\InteractiveTag\index.tsx` 和 `\src\pages\home\project\components\InteractiveSDKList\InteractiveTag\index.tsx` 完全一样，还有另外 2 个组件与这 2 个组件也是高度类似

## 疑问

1. ASR 也需要输入项目 id，是不是为了获取项目关联的热词？

2. 交互名片的使用场景是怎么样子的？

## 项目备注

1. 交互名片的预览路径`private\AIDigitalEmployees\src\pages\home\interactive\components\Rtc\components\RTCPreview\index.tsx`

   > 交互名片的预览没有使用 sdk，所以如果 sdk 修改了不需要回归这里
   > 交互名片的语音识别是直接印用的腾讯的语音识别 sdk，具体使用路径是在`private\AIDigitalEmployees\src\pages\home\interactive\components\Rtc\components\RTCPreview\Model\Recognizer.ts`

2. 交互 sdk 和 一体机 的平台预览路径
   `private\AIDigitalEmployees\src\pages\home\interactive\components\Rtc\components\CommonRTCPreview\index.tsx`

   > 交互 sdk 和 一体机 的平台预览是直接拷贝了一份 RTCsdk 的代码，所以如果 sdk 修改了这里也要同步修改
   > 交互 sdk 和 一体机 的分享链接分享出来的页面是使用的 RTCsdk 包
   > 交互 sdk 和一体机引入 asrsdk 的地方是在
   > `private\AIDigitalEmployees\src\pages\home\interactive\components\Rtc\components\PreviewRtcCore\index.tsx`，

3. asrSDK 是我们在腾讯的 sdk 的基础上做了一层封装，用来做语音识别
4. RTCSDK 是通过调用后台接口，后台调用大模型来获取回答返回给前端，前端再通过 websocket 连接后台获取流数据（包含行为和声音）实时渲染前端界面

5. asrSDK 打包后需要上传到 oss，同时更新 AIDigitalEmployees 项目里面的 asrSDK 的版本号，更新文档，更新页面上 websdk 的 zip 包里面的 asrSDK，更新 RTCSDK 项目里面的 xiaoiceASR_merge.js 文件

## 新旧版 RTCSDK 的区别

1. 拉流这块

- 旧版是通过腾讯的 TRTC.create 创建一个 player，这个 player 去监听事件获取流来驱动 video 播放，以前的流内容包含视频和音频，都是一起推过来的
- 新版是通过 livekit 暴露的 useTracks 暴露的轨道，从轨道中分别找到音频轨道和视频轨道，然后分别驱动，具体的代码逻辑在 private\SDK\LiveKitSDK\src\core\Model\livekit\components\VideoRenderer\index.tsx 里面

2. 初始化

- 旧版是在 useTCRtc.ts 中通过 TRTC.create 初始化播放器，之后调用 enterRoom 方法的时候传入对应的配置
- 新版在项目入口的 index.tsx 中使用 LiveKitRoom 组件初始化，之后通过获取轨道来推流

2. 前后端交互这块

- 旧版是先通过 xhr 去轮询拉回应的文本内容，然后通过 websocket 发给后端，后端再驱动 sdk 的流服务器推流给前端的 sdk
- 新版是直接先调用`/openapi/talk/task/rtc/livekit/start`接口从后端这里获取所有的配置信息，然后在 SDKEffects.ts 里面监听 room 的状态，如果 room 已经连接了，就调用 call 方法处理调用栈，并调用 executeRpcCall，通过 room.localParticipant.performRpc 方法去调用后端的 rpc 接口，然后后端再驱动 sdk 的流服务器推流给前端的 sdk

3. 关键事件的消息监听

- 旧版是通过监听 websocket 消息，包括响应消息中的 type 来判断当前是哪个事件阶段，然后调用响应的回调函数
- 新版是通过 livekit 暴露的 useDataChannel 这个 hook，来监听数据，并根据数据来判断当前是哪个事件阶段，然后调用响应的回调函数

### 阿里云的账号和密码

用户登录名称 chenxuezhong@1687436620736046.onaliyun.com
登录密码 Wangyy0325.

有权限的账号：
vhinteraction@1687436620736046.onaliyun.com
有权限的账号的密码：
upWfBPJpwW8D{PsgHM{Ut5a3{Wb0g|Az

### sentry 账号密码

sentry 账号：chenxuezhong@xiaoice.cn
密码： Wangyy0325.

彭舟的 sentry 账号和密码： pengzhou@xiaoice.cn @Xb123456

### RTC2.0（livekit）

- 在 AIDigitalEmployees 项目中使用的时候，webpack 需要配置 mode: 'development'，才可以作为本地静态文件导入，如果上传到阿里云上就可以直接使用 mode: 'production' 模式打包，具体原因待分析
- 打包发到线上的时候记得将 private\SDK\LiveKitSDK\src\core\Model\livekit\hooks\useRpc.ts 路径下的 DEV_MODE 设置为 false

### tts 模型供应商

```
TTS_XB="xb" // 小冰
TTS_VOLCANO="volcano" // 火山
TTS_MINIMAX="minimax" // minimax
TTS_AZURE="azure" // 微软
TTS_ALI="ali" // 阿里
TTS_ELEVENLABS="elevenlabs" // elevenlabs（已下线）

```

### 根据客户账号（一般是邮箱注册的）去获取用户的 subkey

1. 运营后台：管理中心 - 企业管理 - 输入邮箱，获取企业 openid
2. 数字员工运营平台：硬件管理 - subkey 管理 - 输入上一步获取的 openid，获取企业 subkey

### 根据客户邮箱账号获取临时登录凭证

1. 运营后台：管理中心 - 企业管理 - 输入邮箱，查找到对应企业的信息
2. 点击列表右侧的获取临时凭证，在弹出框里面输入临时访问密钥 xiaobing ，再输入客户邮箱，点击去生成

### 待办

1. 交互 sdk 和互动名片里面的 asr 换成 sdk
2. 所有 sdk 的日志统一管理
3. sdk 的发包使用自动化流程

### 本地服务器启动静态文件

`http-server -p 8888`

### livekit（RTC2.0）初始化的整个流程

```
getconfig -> start 接口 -> 从 start 接口获取 wsUrl 和 token，赋值给 LiveKitRoom 组件 -> 监听 room state 的状态，如果连接上了，就调用 RPC 初始化连接 agent（这个阶段触发 onJoinRoom 等回调） -> 监听视频和音频轨道，如果监听到了轨道，且状态改变为可用（true），即完成所有的启动流程
```

### 微信小程序 jssdk 监听页面隐藏

```ts
WeixinJSBridge.on('onPageStateChange', (res: any) => {
  console.log('res is active', res.active);
  if (!res?.active) {
    handle.cutLine();
  }
});
```

### 易企聊小程序 appid

本地调试使用 wxbd8da6752f929b40
prod 使用 wx65eba4bff5c43988

### 需要更新的 sdk

1. rtc1.0 更新了语言的处理，需要在 sdk 的 zip 总包里面更新
2. rtc2.0 更新正式环境和 zip 包，项目代码里面使用的需要更新为正式环境的之后再上线
3. 3dsdk 需要更新正式环境和 zip 包，model_verify.html 文件里面引用的那个不知道是如何打包的
4. asrsdk 需要更新正式环境和 zip 包
5. 生命周期 onJoinRoom 的参数中加入 roomeName 和 agentId

### 3dsdk 更新内容

1. 生命周期 onInited 返回的数据增加 vh_facial_list ，表示数字人支持的表情序列；
2. 升级长文本驱动方法 talkLongText，支持文本中嵌入动作表情标签；
3. 新增流式文本驱动方法 driveTalkEmotionActionStream，可支持流式文本中嵌入动作表情标签；
4. 新增驱动数字人表情方法 playEmotionList；
5. 下线文本驱动方法，仅保留长文本驱动、流式文本驱动方法
6. 新增 onInteractionStart 生命周期，表示启动交互成功；
7. 初始化新增 showLog 参数，表示是否在浏览器控制台打印完整日志，默认为 false；
8. 新增 drivePerform 综合接口，支持通过不同的传参模式，驱动执行不同的接口
9. 新增 mute 属性用于配置数字人初始静音状态
10. 新增 switchMuteStatus 方法用于切换数字人静音状态

### rtcsdk 更新内容

升级内容：

1. RTC-SDK 文本驱动 Client.talk 方法第二个参数新增 transParams 属性配置，用于透传数据
2. 初始化新增 showLog 参数，表示是否在浏览器控制台打印完整日志，默认为 false；
3. 新增 onNetworkStateChange 生命周期，用于获取当前 sdk 连接状态
4. 新增 onVideoReady 视频流订阅成功生命周期
5. 生命周期 onJoinRoom 的参数中加入 roomeName 和 agentId

### rtc 每次更新都要在《数字员工-OpenAPI&SDK 线上支持》这个群的群公告里面更新，并@朱虹，思操，产品

### rtc 视频和音频的流信息查看

edge://webrtc-internals/

### 3d 数字人说话的逻辑

- json 配置的 morphInfluences 数据（object 格式，存的是形态键名和权重值），转换成了 2 份数据，
- 一份是 talkMorphNames（里面存的是对象的 key 的数组），
- 另一份是 talkMorphNamesInfluence（就是 morphInfluences），
- 在 character.ts 文件里面，会根据 talkMorphNames 转换出 this.toPlayTalkMorphNames，其实就是创建一个对象，然后遍历 talkMorphNames，存储每个 name 对应的索引值：比如：{"jawForward": 0, "mouthLeft": 1}；（这个顺序很重要，后面接口返回的形态键的索引就是按这个顺序来的，所以在 json 配置里面就要处理好这个顺序）
- talk 的时候先调请求接口获取每一帧的对应的每个形态键的变化值，但给的是索引，如：{0：0.03, 1：0.4};
- 遍历 toPlayTalkMorphNames 这份数据，拿到之前处理好的键名和对应的索引，这个索引就直接可以从去接口返回的数据里面根据索引来获取形态键的变化值，键名就可以去 morphInfluences 里面匹配对应的权重值，2 个数据相乘的结果 A 就是对应变形目标的最终要变化的值
- 上一步的结果 A 要赋值给每个变形目标（morphTargets 里面存着所有的变形目标）里面对应的形态键（形态键都存放在每个变形目标的 morphTargetInfluences 里面，但这里面是{索引：值}的一种数据结构，需要先根据形态键名去每个变形目标的 morphTargetDictionary 里面找到其在 morphTargetInfluences 里面对应的索引，然后再去改对应的值）
- 总结，配置的 json 数据里面的 morphInfluences 需要匹配接口返回的索引顺序，方便后面找到每个形态键需要改变的值

### 3d 的 isMesh 的意思

是否是网格体

### 3dsdk 的 sourcemap 打包相关配置

webpack.config.js 的 prod 正式包要换成这个

```
filename: "xiaoiceThreeDimensionSDK1.0.1.js", //决定bundle输出名称
urlPrefix: '~/interaction/public/js/sdk/release/'

```

### 形态键的意思

```
jawForward: 下巴向前移动。
jawRight: 下巴向右移动。
jawLeft: 下巴向左移动。
jawOpen: 下巴向下移动（张嘴）。
mouthClose: 嘴巴闭合。
mouthFunnel: 嘴巴呈漏斗状（类似发出“哦”音时的嘴型）。
mouthPucker: 嘴巴撅起（类似发出“嘟”音时的嘴型）。
mouthRight: 嘴巴向右移动。
mouthLeft: 嘴巴向左移动。
mouthSmileLeft: 左侧嘴角上扬（微笑）。
mouthSmileRight: 右侧嘴角上扬（微笑）。
mouthFrownLeft: 左侧嘴角下垂（皱眉或悲伤）。
mouthFrownRight: 右侧嘴角下垂（皱眉或悲伤）。
mouthDimpleLeft: 左侧脸颊出现酒窝。
mouthDimpleRight: 右侧脸颊出现酒窝。
mouthStretchLeft: 左侧嘴角向外拉伸。
mouthStretchRight: 右侧嘴角向外拉伸。
mouthRollLower: 下嘴唇向内卷。
mouthRollUpper: 上嘴唇向内卷。
mouthShrugLower: 下嘴唇向下收缩。
mouthShrugUpper: 上嘴唇向上收缩。
mouthPressLeft: 左侧嘴唇用力压紧。
mouthPressRight: 右侧嘴唇用力压紧。
mouthLowerDownLeft: 左侧下嘴唇向下移动。
mouthLowerDownRight: 右侧下嘴唇向下移动。
mouthUpperUpLeft: 左侧上嘴唇向上移动。
mouthUpperUpRight: 右侧上嘴唇向上移动。

```

### livekit 支持的浏览器版本

safari >= 11.1
ios_saf >= 11.3
chrome >= 64
and_chr >= 64
android >= 64
firefox >= 58
and_ff >= 58
edge >= 79
Opera >= 52
Samsung >= 9.2
not IE 11
not dead

### ngrok key 32pY8cEXICDL32qv8F6cr3Sba9b_2dXcPUHonqhcSkooq7DWe

## 客户反馈问题与可能原因记录

1. rpc 调用失败
   ：如果查看日志，失败的原因是： code：1501， message：连接超时，那么就需要看下网络连接状态，因为这种既有可能是客户网络差导致的连接超时
2. 数字人说话的时候一卡一卡的
   ：先看下是不是 30 天没有使用导致的冷数据，如果是冷数据的话，需要后端取回
   ：如果不是冷数据，看看素材的分辨率，如果素材的分辨率过大，比如 4k，码率过大就会导致解码来不及，造成卡顿；分辨率信息可以在 get 接口查看
