```js
parserOptions: {
  project: require('path').join(__dirname, './tsconfig.json')
},
```

```js
!(function (window) {
  const host = 'https://aibeings-vip-int.xiaoice.com',
    url =
      host +
      '/CRTCPreview/8b0a70f45d154fc7a4cd90f0bb772ce0?sign=ZXlKaGJHY2lPaUpJVXpJMU5pSjkuZXlKd1lYbHNiMkZrSWpvaWUxd2lZMjl0Y0dGdWVVbGtYQ0k2WENKbVpqbGxaV1EyWkMweU16TXhMVFEwWm1ZdE9XWmpZUzAzWkRkak1EWXpNREJoWlRsY0lpeGNJbWxrWlc1MGFXWnBZMkYwYVc5dVNXUmNJanBjSWpJell6WTRPV1V6TFRRek1tTXRNVEZsWlMwNE5ETXhMVFprTXpCaE1ESTFOVGN4TUMxcGJuUmxjbUZqZEdsMlpTMWlZV05yWlc1a1hDSXNYQ0owYjJ0bGJrbGtYQ0k2WENKa05qUXpZak00WlRsbU0yUTBaRGhsT0RrNU56STFaVEptWVdGaE9XRm1ZbHdpZlNJc0ltbGhkQ0k2TVRjMU1qVXdPRGs1Tnl3aVpYaHdJam95TmpFMk5UQTRPVGszZlEuZnluZU44b1pKVEhNU085RjZNMVVnbXU4RXVMMXBZbmlyTGhQbGNCZVpTVQ==&isIFrame=1';
  const wrapDiv = document.createElement('div');
  wrapDiv.id = 'xiaoice-streaming-embed';
  const container = document.createElement('div');
  container.id = 'xiaoice-streaming-container';
  const stylesheet = document.createElement('style');
  const clientWidth = document.body.clientWidth;
  stylesheet.innerHTML =
    ' #xiaoice-streaming-embed { z-index: 9999; position: fixed; right: 60px; bottom: 60px; width: 200px; height: 200px; border-radius: 50%; border: 2px solid #fff; box-shadow: 0px 8px 24px 0px rgba(0, 0, 0, 0.12); overflow: hidden; } #xiaoice-streaming-embed.horizontal { height: 366px;  width: calc(366px * 16 / 9); border: 0; border-radius: 12px; box-shadow: 0px 20px 20px 0px rgba(0, 0, 0, 0.10); } #xiaoice-streaming-embed.vertical { height: 680px;  width: calc(680px * 9 / 16); border: 0; border-radius: 12px; box-shadow: 0px 20px 20px 0px rgba(0, 0, 0, 0.10); } #xiaoice-streaming-container { width: 100%; height: 100%; } #xiaoice-streaming-container iframe { width: 100%; height: 100%; border: 0; }';
  const iframe = document.createElement('iframe');
  iframe.allowFullscreen = !1;
  iframe.title = 'Streaming Embed';
  iframe.role = 'dialog';
  iframe.allow = 'microphone';
  iframe.src = url;
  iframe.onload = () => {
    const watchDiv = document.getElementById('xiaoice-streaming-embed');
    const resizeObserver = new ResizeObserver(() => {
      iframe.contentWindow.postMessage({ action: 'resize' }, '*');
    });
    resizeObserver.observe(watchDiv);
  };
  window.addEventListener('message', e => {
    if (e.origin !== host) return;
    if (e.data.action === 'start') {
      if (e.data.ratio === 'horizontal') {
        wrapDiv.classList.toggle('horizontal', true);
      } else if (e.data.ratio === 'vertical') {
        wrapDiv.classList.toggle('vertical', true);
      }
    } else if (e.data.action === 'close') {
      wrapDiv.classList.toggle('horizontal', false);
      wrapDiv.classList.toggle('vertical', false);
    }
  });
  container.appendChild(iframe);
  wrapDiv.appendChild(stylesheet);
  wrapDiv.appendChild(container);
  document.body.appendChild(wrapDiv);
})(globalThis);
```

- https://github.com/livekit/client-sdk-js/tree/main
  这个仓库切出去之后视频断流的问题解决

- copilot 的权限申请

- 熟悉项目的视频文件

- 切换到彭舟的分支看下 vite 的改造

- 找限哥了解下 livekit sdk 的相关内容

- 回溯拷贝 sdk 的理由

- 本地改改项目看看开发环境效果

本周工作：

- 搭建前端开发环境，申请相关权限
- 熟悉数字员工项目和代码
- ASR sdk 与 wix 平台兼容性问题定位与反馈
- 数字播放工作台预览问题处理

下周工作：

- 熟悉 sdk 相关代码
- 交互预览升级 RTCSDK2.0 需求评估与开发

---

---

---

文档中的流程简图需要更新https://aibeings-vip.xiaoice.com/developer-doc/show/164

state.globalImage
state.globalVideo
state.caption
TransparentVideo

了解 webgl

private\SDK\aidigSDK\src\core\SDKEffects.tsx 下的 handleDo 挂了 300 秒，可以用 fetch keep-alive 优化

private\SDK\aidigSDK\src\core\types\types.ts 下的 heartText 的 PING 和 PONG 的值一样，是不是写错了

### asr sdk

- asrsdk 加 sentry 上报，识别前和识别后的相关信息都要上报

- 直接把腾讯 asr 的代码拷贝到本地，改下逻辑，支持在一句话结束的时候返回音频，顺便改下支持给 websocket 传参（要支持降噪）

### rtc 和拷贝的那份的区别

> 先和产品确认下预览和分享链接的权益扣减是怎么计算的

1. 建立 websocket 连接以进入房间的时候，ws 的地址是相同的，2 个 signature 传参不同，sdk 里面是拿的连接上的 shortSign，拷贝的是拿的 cookie 里面的登录信息
2. 启动接口， askStream， getStream 等接口都不一样

- 总结：2 者的 websocket 链接的 url 一样，但是用户认证的参数不一样
- 2 者的 http 请求的接口都不一样，sdk 是通过在请求头里配置 signature 来验证用户的，拷贝的是通过 cookie 验证用户的

# 代办事项

1. 互动卡片和交互 sdk 的预览里面的 ASR 也是自己封装的，这个也需要处理，暂时放到后面迭代处理
1. 互动卡片和交互 sdk 的预览替换 rtc2.0，需要整理下 rtc2.0 里面使用到的接口
1. ASR 使用新的包，添加 sentry，获取音频，上报，同时暴露降噪（noise_threshold）的传参(这个参数可以直接传，不过用户还不知道)，ASR 应该是有对腾讯 sdk 的源码进行修改的，应该主要是改了那些连接后台的域名，同时修改打包方法，上报的时候加一个时间戳 timestamp
1. rtc2.0 的 talk 方法添加 extra 参数，透传 ok
1. rtc2.0 开场白场景的画面上的文字不显示问题修复 ok

1. 找下 livekit 配置 页面隐藏不断流的 room 的入口 ok
1. 找下 rtc2.0 使用的接口的配置

```js
// 还要考虑小程序使用的场景，只有互动名片里面才有小程序，是直接将url上的'appletLoginSessionId'写进cookie的appletLoginSessionId里的也是会做权益的扣减
// 小程序的场景，目前主要的区别是，1. 需要将用户的身份认证信息放到cookie里面；2. 在1.0版本中，创建TRTC实例的时候必须先触发视频播放才可以；3. 几个关键步骤后，小程序需要进行单独上报

// 1.0的websocket地址是一样的，预览的时候token直接传的cookie
// 'rtc-livekit-aibeings-int.xiaoice.cn/rtc' 这个websocket的地址是在start接口里面获取的，然后在livekt-room 组件初始化的时候传入，是算法那边提供的
websocket: 'wss://rtc-livekit-aibeings-int.xiaoice.cn/rtc?access_token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJpZGVudGl0eV9kMGQ2NzFiZDA5MjU0MDIxYjM5ZjhjMTI1OWJkY2M4ZSIsImlzcyI6ImxpdmVraXQiLCJuYW1lIjoibmFtZV94IiwidmlkZW8iOnsicm9vbUpvaW4iOnRydWUsInJvb20iOiJSb29tTmFtZV83MDJjMGYyNjkxMDc0MDFiOGRlOWEyZjQ3ZWY5MjI4YyJ9LCJzaXAiOnt9LCJleHAiOjE3NTM0MDg2ODAsImp0aSI6ImlkZW50aXR5X2QwZDY3MWJkMDkyNTQwMjFiMzlmOGMxMjU5YmRjYzhlIn0.uJMxS1nK1G-zyQln9AoPsn3WJOAjGI8zETMOX2_Mig0&auto_subscribe=1&sdk=js&version=2.11.4&protocol=15';

// xhr:

// 获取项目的详细配置（在 SDKEffects.tsx 文件中初始化配置的时候调用）：
// 这个接口SDK1.0使用的就是这个，预览那边使用的则是 /talk/project/get
// 引入路径在private\SDK\LiveKitSDK\src\core\SDKEffects.tsx 的 getConfig 方法
getInteractiveDetail: '/openapi/talk/rtc/get?projectId=42f068fc95774826a68cc4fc2ab5b9e9';

// 通过虚拟人id获取项目id，这个1.0的时候也有，预览的时候一定会有项目id，
// 引入路径在private\SDK\LiveKitSDK\src\core\SDKEffects.tsx 的 initConfigPre 方法
getProjectByHumanId: '/openapi/talk/rtc/project/get';

// livekit 启动接口（RTCInteraction._startRTC 方法调用）：
// 引入路径在private\SDK\LiveKitSDK\src\core\SDKEffects.tsx 的 beginStart 方法
// 1.0 的启动接口有2，分别是web端'/talk/task/rtc/sync/start'和小程序端'/applet/rtc/rtc/sync/start'
// 2.0 是启动之后监听room的状态，然后调用源码的api传入参数驱动数字人
// 1.0 则是调用start接口之前先初始化websocket，然后调用socket的send api去发送数据驱动数字人
startLivekit: '/openapi/talk/task/rtc/livekit/start';

// livekit关闭接口：
// 引入路径在private\SDK\LiveKitSDK\src\core\SDKEffects.tsx 的 useEffect 和 页面关闭之前的回调里面使用
stopLivekit: '/openapi/talk/task/rtc/livekit/stop';

// 上报接口（预览是否不影响，不用上报）：新的上报接口
postLivekitReport: '/openapi/cost/livekit_ptest/event';

// 上报，旧的上报接口，目前也有使用，可以确认下是否可以只留一个上报接口
postCostReport: '/openapi/cost/report';
```

- 1.0 下使用的接口

https://aibeings-vip-int.xiaoice.com/api/v1/talk/task/rtc/sync/start 预览走数字员工的域名 interactive-virtualhuman-int.xiaoice.com/ 分享链接

```js
// 根据虚拟人id获取项目id
sdk： `/openapi/talk/rtc/project/get`
交互sdk 无，直接使用项目id
名片 无，直接使用链接上的项目id
名片小程序 无，直接使用链接上的项目id

// 获取项目的详细配置，这个接口现在新旧版本的sdk使用的是一样的接口，预览使用的应该也可以复用
sdk: '/openapi/talk/rtc/get'
交互sdk： '/talk/project/get'
名片： '/talk/project/get'
名片小程序： 'applet/project/info?projectId='

// websocket接口，需要注意不管是sdk还是预览还是小程序，身份认证信息都是放在token里面使用，但是用tokenType区分不同环境的认证信息
一致： `/openapi/interactive/websocket_v2406?taskId=${taskId}&token=${token}&tokenType=${tokenType}`

// 启动接口
sdk： '/openapi/talk/task/rtc/sync/start'
交互sdk: '/talk/task/rtc/sync/start';
名片：'/talk/task/rtc/sync/start'
名片小程序： '/applet/rtc/rtc/sync/start'

// 询问，2.0中无此类接口
sdk： '/openapi/talk/askStream'
交互sdk： '/talk/faq/askStream'
名片 '/talk/faq/askStream',
名片小程序 `/applet/talk/askStream`,

// 获取流式答案，2.0中无此类接口
sdk: '/openapi/talk/getStreamAnswer'
交互sdk： '/talk/faq/getStreamAnswer'
名片  '/talk/faq/getStreamAnswer',
名片小程序 `/applet/talk/getStreamAnswer`,

// 关闭接口
sdk `/openapi/talk/rtc/stop`
交互sdk '/talk/task/rtc/stop'
名片 '/talk/task/rtc/stop'
名片小程序 '/applet/rtc/rtc/stop',

// 上报接口
sdk '/openapi/cost/report'
交互sdk： '/cost/report'
名片 '/cost/report'
名片小程序 `/datareport/appletUpload` // 小程序上报是有单独的上报时期，与正常的上报不冲突


```

7. 了解下 ARS 自己打包后为什么那样子不能直接使用 new
8. ARS sentry 上报上传的时候是否需要拆分？：不用，直接在一句话结束的时候就上报

```ts
import { arrayBufferToBase64, pcmToWav } from './utils';
 noise_threshold?: number;
 // 慎用，噪音参数阈值，取值范围[-1, 1]，取值越大，判定为噪音情况越大。取值越小，判定为人声情况越大，如果要调，建议 0.333/0.5/0.666 这3个数值
    if(this.config.noise_threshold) {
      recognizerParams.noise_threshold = this.config.noise_threshold;
    }
 // 录音结束
    webAudioSpeechRecognizer.OnRecorderStop = (res: Int8Array)=>{
      if(res.length > 0) {
        const arrayBuffer = new Int8Array(res).buffer;
        const wavData = pcmToWav(arrayBuffer, 16000, 16, 1);
        const baseData = arrayBufferToBase64(wavData);
        const blob = new Blob([wavData], { type: 'audio/wav' });
        const url = URL.createObjectURL(blob);
      }
    };

```

```ts
// global.d.ts
declare global {
  interface Window {
    AsrSDK: any;
  }
}

export {};
```

```ts
// index.ts
import * as Sentry from '@sentry/browser';

Sentry.init({
  dsn: 'https://1e77e25824b8bd05a0cd2fdce33068b8@aic-sentry.xiaoice.cn/8',
  // Setting this option to true will send default PII data to Sentry.
  // For example, automatic IP address collection on events
  sendDefaultPii: true,
});

// Sentry.captureException()
```

9. 集成交互的嵌入 HTML 的图片要替换
10. 交互 sdk 支持分辨率切换： ok
11. asr 里面是不是要给腾讯的 sdk 加个单例模式？

定位不显示的开场白文字问题
自己先写下那个 sdk2.0 兼容代码

- ASR 开发完了，更新了源码包，修改了下源码
- 对话文本不显示的问题也找到了，无限那边修改了代码导致的。
- 刚才集成 SDK 的问题用户说没时间，还没处理，不过用户应该不是专职开发
- 交互 sdk 的分享链接和集成的开发完了，现在在做 livekit2.0 的兼容处理，交互 SDK 和互动名片接口和流程的梳理
  然后产品还加了 3 个小需求，一个时 sdk 预览页面加清晰度切换功能，一个是根据现在集成 sdk 线上问题的处理，产品想更新下示例图片，再看下能不能支撑下集成 sdk 灵活使用的场景更新在文档里；talk 方法支持透传参数

```js
// action 标签： name 是动作名列表， loop 是循环播放次数（默认不传是1，传0就是不播放动作），如果小于0（比如：-1），就是在当前标签控制的语音期间无限循环播放
// emotion 标签： name 是表情名，表示在当前标签控制范围内的语音里展示的表情
`<action name="["hello", "no"]" loop=1><emotion name="happy_M">今天天气真好，</emotion><emotion name="sad_M">晴空万里，</emotion></action>我真的好喜欢，<action name="["shitou", "no"]" loop=1><emotion name="happy_M">你们喜欢这个天气和环境吗？</emotion></action>我反正是很喜欢。`;
```

1.0 的 websocket： wss://interactive-virtualhuman.xiaoice.com/openapi/interactive/websocket_v2406

1. 判断下可不可以复用 character 里面的 playMotionStatic 主动播放表情
2. 了解下为什么 character 里面的 resetTalkMorph 这个方法不起作用
3. character 里面的 playTalk 方法如果要实现语音嵌套动作和表情，需要修改下逻辑

- 修改 3dsdk 的本地测试环境

```js
axios/config 改 env
axios/service 改 subkey
test/index.js 改项目 id 和 env
```

模型中表情通常是通过 morphTarget（变形目标）实现的，而动作是通过骨骼动画实现的。当调用 playEmotions 时，实际上需要设置模型的 morphTargetInfluences 属性，而不是执行动作。

Webkit 537.36 Chrome 122.0.6261.119
LiveKit doesn't seem to be supported on this
browser. Try to update your browser and make sure
no browser extensions are disabling webRTC.

```json
{
  "fps": 15,
  "orbitControls": {
    "enablePan": true,
    "enableZoom": true,
    "enableRotate": false,
    "enableRotateX": false,
    "enableRotateY": false
  },
  "loaders": {
    "gltf": {
      "dracoLoaderPath": "/draco/gltf/"
    },
    "hdr": false
  },
  "camera": {
    "type": "perspective",
    "left": -1,
    "right": 1,
    "top": 2.222,
    "bottom": -1.333,
    "fov": 30,
    "near": 0.1,
    "far": 1000,
    "position": [0, 0.2, 10],
    "focus": [0, 0.2, 0],
    "rotation": [10, 2, 0],
    "zoom": 1.9
  },
  "lights": [
    {
      "type": "DirectionalLight",
      "color": "0xFFFFFF",
      "intensity": 0.2,
      "position": [-5, 5, 5],
      "castShadow": false
    },
    {
      "type": "AmbientLight",
      "color": "0xFFFFFF",
      "intensity": 3,
      "position": [-5, 5, 5],
      "castShadow": false
    }
  ],
  "characterOptions": {
    "blinkMorphNames": ["eyeBlinkLeft", "eyeBlinkRight"],
    "position": [0, 0, 0],
    "scale": [1, 1, 1]
  },
  "toneMappingExposure": 1,
  "morphInfluences": {
    "jawForward": 0.6,
    "jawRight": 0.6,
    "jawLeft": 0.6,
    "jawOpen": 1,
    "mouthClose": 0,
    "mouthFunnel": 1,
    "mouthPucker": 1,
    "mouthRight": 0.6,
    "mouthLeft": 0.6,
    "mouthSmileLeft": 0.6,
    "mouthSmileRight": 0.6,
    "mouthFrownLeft": 0.6,
    "mouthFrownRight": 0.6,
    "mouthDimpleLeft": 0.6,
    "mouthDimpleRight": 0.6,
    "mouthStretchLeft": 0.6,
    "mouthStretchRight": 0.6,
    "mouthRollLower": 0,
    "mouthRollUpper": 1,
    "mouthShrugLower": 0,
    "mouthShrugUpper": 1,
    "mouthPressLeft": 0.6,
    "mouthPressRight": 0.6,
    "mouthLowerDownLeft": 0,
    "mouthLowerDownRight": 0,
    "mouthUpperUpLeft": 1,
    "mouthUpperUpRight": 1
  }
}
```

1. 问三庆 /openapi/talk/queryInteractiveVirtualHuman/byBizId/v2 接口获取的数据中的字段 virtualHumanModeInfo 中的 configLink 和 modelLink 获取的 morphInfluences 数据不一致

- 问三庆有没有开场白能显示表情的示例 ok
- 问三庆，长文本加入表情为什么没有效果
- 问三庆，是不是没法打断正在执行的动作
- configLink 中获取到会少很多表情，导致最后在重置的时候没法找到，有些表情重置失败
- 解决办法，自己从 modelLink 里的 gltf 里面取获取 morphInfluences 数据，需要去重

2. 问产品，每个表情需要做多久？比如表情序列里面有 3 个表情，那每个表情需要展示多久？: 每次只能传一个表情，如果传了下一个表情就过渡到下个表情，如果传了空值就变成默认状态

3. 重置方法 resetTalkMorph 里面需要完善表情的重置逻辑，这里因为第一点说的接口返回的表情列表不一致，导致有些表情没法被重置
4. 开场白的动作总是在说完话之后才执行，而且有时候会触发，有时候不会，这个需要处理，原因是 this.queueActions 被清空了，而且有时候是说完话做动作，有时候是说话的时候做动作，需要处理
5. 表情的逻辑可以借鉴 resetTalkMorph 方法里面的做过渡处理
6. 长文本驱动文本+动作不起作用要看看什么原因
7. 备注：表情处理就是改 mesh.morphTargetInfluences 里面的值，动作处理就是改 queueActions 的值

8. 动作没法执行是不是因为被提前清空了？每次执行完一个动作都会从队列中删除，为什么还要做一次性清空的动作: 可能会有需要某个动作在整个播放过程都保持循环的情况存在，如果这样的话就需要在话说完的时候清空
9. ai 搜一下动作为什么会延迟执行，是不是每次都在 finish 时间后执行？有没有其他执行时机？

10. 问下产品，当前项目的表情模板是产品在运营平台配置的，前端在 configLink 中获取的，是否会有不匹配的问题

rtc-livekit-aibeings.xiaoice.cn

本周工作

- 交互 sdk 预览页面加清晰度切换功能，并更新集成连接使用示例图片
- RTC2.0 talk 方法增加透传参数
- RTC2.0 预览和小程序使用场景接口对齐
- 3dsdk 需求开发

下周工作

- 3dsdk 需求开发提测
- 交互 sdk 预览，互动名片接入 RTC2.0
- 易企聊需求熟悉和预研

说完话嘴型没还原的问题: done
动作没完全展示完全就匆匆结束，因为后面估计接了 idle 动作，所以动作展示不完全
动作跟着语音说完就结束了，没法展示后面的动作: done

- 尝试在会话的动作执行的过程中，如果下一个动作是 idle 动作，先不执行

```ts
const prevActions = this.getWeightActions();
// 如果当前有在播放中的动作，同时此次要播放的动作是从idleActions里面选择来播放的，则不执行任何操作
if (prevActions.length > 0 && fromIdleAction) {
  const prevActionNames = prevActions[0]?.name;
  if (!this.isActionCompleted(prevActionNames)) {
    console.log(
      `当前正在播放中的动作是${prevActions[0].name}，此次要播放的动作是来自idle的动作${name}，所以不执行任何操作`
    );
    return;
  }
}
```

- 如果当前语音有动作，就马上执行动作
- 如果当前语音没有动作，就执行配置的默认语音动作
- 如果当前语音没有动作，也没有配置的默认语音动作，就等上一个语音绑定的动作全部结束后(如果是循环动作，就一直播放)，做 idle 动作
- 如果当前会话的所有语音都结束了，就等最后一个语音绑定的动作结束后，执行 idle 动作
  > 这里如果上个语音动作是无限循环的动作，那么只等最后一个语音延续到当前语音的单个动作做完后就开始执行 idle 动作

公司对外的营销渠道都有哪一些
如果,当前语,音没有,动作，也,没有配置的默认语音,动作，

```js
`<action name="['hello', 'no']" loop=-1>
  <emotion name="happy_M">我现在在说第一部分的第一句话，第一部分的动作是hello和no，无限循环，第一句的表情是happy，</emotion>
  <emotion name="sad_M">现在是第一部分的第二句话，第二句的表情是sad。</emotion>
</action>
<emotion name="happy_M">现在是第二部分，没有配置动作，表情是happy。</emotion>
<action name="["shitou", "bu"]" loop=1>
  <emotion name="happy_M">现在是第三部分，只有一句话，动作是石头和布，循环一次，表情是happy。</emotion>
</action>
现在是第四部分，没有动作和表情。
<action name="["beishou", "bixin"]" loop=1>现在是第五部分，也是最后一部分，动作是背手和比心，循环一次，没有表情。</action>`;
```

- 立即播放动作的备份

```js
playActionImmediately: async (actionList: string[], forceImmediate = false) => {
      if (!actionList?.length) return;

      const character = glbRef.current.getCharacter();

      // 如果需要强制立即播放
      if (forceImmediate) {
        // 中断所有当前动作
        const currentActions = character.getWeightActions();
        for (const action of currentActions) {
          action.break();
          // 直接降低权重以立即停止视觉效果
          action.action.setEffectiveWeight(0);
        }
      }

      // 清空队列
      character.queueActions = [];

      // 设置队列中的后续动作
      if (actionList.length > 1) {
        character.queueActions = actionList.slice(1);
      }

      // 立即播放第一个动作
      const curAction = actionList[0];
      await character.playAction(
        curAction,
        forceImmediate ? 0.1 : 0.6 // 如果是强制立即播放，使用更短的过渡时间
      );
    },
```

1. 切换分辨率的需求要看下是否有使用在对的地方：一个是初始化 RTC 接口的时候，一个是在使用 start 接口的时候：ok，start 接口使用的就是初始化的时候传入的数据
2. 看下 2.0 的接口参数的区别
3. 打点信息

- SDKEffects.ts --> getNewAnswer 方法里面 push 了上报信息
  frameTimeLogList.current.push({
  type: 'query',
  content: text,
  sessionId: sessionId,
  current_time: new Date().getTime()
  })
- SDKEffects.tsz sendMessage 方法里面 push 了上报信息
  if (type !== 'heartbeat') {
  frameTimeLogList.current.push({
  type,
  content: text,
  sessionId: socketId,
  fragment_id: socketFragmentId,
  current_time: new Date().getTime(),
  wait: wait ? true : false
  })
  }
- SDKEffects 1118 行的 judgeSEIPayload 方法里面将之前的打点信息统一通过 sentry 上报了
  //记录峰值时间用来打点
  frameTimeLogList.current.push({
  type,
  content,
  sessionId: id,
  fragment_id,
  current_time: new Date().getTime()
  })
  type === FrameEnum.FIRST_FRAME：即首帧加载回来的时候
  sentry.report?.warning + postCostReport 打点

3. postCostReport 里面的 publishType 是不是都设置成 common
4. 接入之后，回答问题的首句从 onTalkStart 回调里面去取，后面的内容从 onStreamData 里面去取

### 互动名片里面的不同点

#### SDKEffects 里面

1. cardInfo ： 业务逻辑，h5 和小程序会有不用的卡片信息接口
2. 整合了 asr 的逻辑，

- 包括 speakMode 这种持续监听语音或微信点击按钮才会说语音的逻辑
- 语音识别的逻辑是放在`if (type === FrameEnum.LAST_FRAME)`这种逻辑里的，后面要处理成放在 livekit 的回调里，可以参考交互 sdk

3. 空闲 20s 后就会播放结束语
4. 小程序场景下的上报
5. sentry 的上报
6. FrameEnum.FIRST_FRAME 里面的代码放到 onTalkStart 里面处理，上报信息已有的就不做处理了
7. FrameEnum.LAST_FRAME 里面的代码放到 onTalkEnd 函数里面处理，上报信息已有的就不做处理了

#### RTCPreview 里面

1. 有个小窗模式
2. 有个红包雨的功能
3. 视频播放做了自定义: 相关的信息在 onStreamData 这个回调里有返回
4. 挂载元素的外面可以再套一层元素，因为挂载元素的样式计算也是从获取配置信息那个接口拿的
5. 上报的先不管，后面统一处理

6. 有一个 state.liveOrMatt 没法设置，不过这个在 2.0 里面也有，看看可不可以忽略

7. 确认结束语能否正常执行
8. 确认每句说完的结束回调是否有
9. 结束用语的逻辑交互 sdk 里面也要补充

```xml
<action name="['hello', 'bixin']" loop=-1><emotion name="happy_M">我现在在说第一部分的第一句话，第一部分的动作是 hello 和 比心，无限循环，第一句的表情是 happy，</emotion><emotion name="sad_M">现在是第一部分的第二句话，第二句的表情是 sad。</emotion></action><action name="["beishou", "bixin"]" loop=-1><emotion name="happy_M">现在是第二部分，动作是背手和比心，无限循环，表情是 happy。</emotion></action><emotion name="happy_M">现在是第三部分，没有配置动作，表情是 happy。</emotion><action name="["shitou", "bu"]" loop=1><emotion name="happy_M">现在是第四部分，只有一句话，动作是石头和布，循环一次，表情是 happy。</emotion></action>现在是第五部分，没有动作和表情。<action name="["beishou", "bixin"]" loop=1>现在是第六部分，也是最后一部分，动作是背手和比心，循环一次，没有表情。</action>
```

<speak>在<say-as interpret-as="date">2022-12-31</say-as>元旦前，<say-as interpret-as="address">北京</say-as>某中学的语文课堂上同学们都按奈不住激动地心情，等待着<sub alias="元旦">01.01</sub>假期的到来。随着<w>下课铃</w>响起学生们一个个<phoneme alphabet="py" ph="ji2 mang2 de5">急忙地</phoneme>收拾东西。此时<break time="3s"/>班主任<say-as interpret-as="name">单老师</say-as>进来了。</speak>

10. 互动名片的小程序的文字聊天窗口还需要适配
    q=https%3A%2F%2Faibeings-vip-int.xiaoice.com%2Fapplet%3FprojectId%3De26f3e64f6d845549ec4acdf9b323df4
11. 点击通话然后马上挂掉还是会进入的问题
12. 确认获取录音权限的弹窗的大小问题

13. 看下产品测试提的问题
14. 交互 sdk 和互动名片的上报逻辑完善
15. 易企聊需求开发

16. 3dsdk 的录屏给产品看 ok
17. 3dsdk 的表情统一使用连续传多个表情的 api: ok
18. rtc1.0 的语言传参问题 ok
19. rtc2.0 的 tts 模型传参问题，看下供应商的内容是怎么传过去的，数字人不展示的，看看是权益用完了还是 int 环境配置有问题 ok
20. 互动名片的字幕的播报逻辑要改
21. 3D 数字人动作变形的原因是因为有 2 个动作叠加在了一起，比如当前播放的明明是 hello，却还有一个 idle 也在播放，而且 idle 动作的 enable 和 isEffective 都为 true，weight 值为 1
22. 火山的 tts 还不支持 rtc2.0，问下思操后面上正式环境了怎么办

23. 看下 3dsdk 流式播放顺序的问题: ok；更新 asr 和 rtc 的文档；ok；看下产品 rtc 拉流为什么失败；上报日志数据完善；互动名片小程序接口联调；字幕问题；3dsdk 的驱动文本这个 api 要隐藏不对外暴露；ok；demo 里的 ssml 这个文案要改下：ok；

24. 字幕跟不上问题；ok；字幕展示不全问题；ok；日志问题；ok；小程序环境下的 title 修改问题；ok；
    小程序环境下 stop 有没有调用问题；
    int 环境下拉流失败问题；添加日志看看
    rtcsdk 在拉流重试的时候直接挂断，然后再次 start，前面的重试流程不会中断，还会继续，后面重试失败了，会直接触发 error；---测试下

25. 拉取 tts 正则信息的接口还需要一个小程序环境的
26. 前端 rtc2.0 加入 sentry 日志上报
27. 加入视频流加载成功的钩子，
28. 添加音频流加载成功的钩子

801ddeed0cbd46dab4c92ac9d2c67617

e59fcc6832224d7da6a130c6cc817999

sessionId： 4951e913-428f-492a-a81e-e24520748361

宁夏公司的信息
账号： 31404183@qq.com
subkey： 591762c9d1b04dfd93d8c0f48e8e0296
项目 id： ba888416-f030-11ef-9aeb-830d3f2907db

```js
[
  { name: '中文', pattern: '[\\u4e00-\\u9fa5]', value: 211 },
  { name: '数字', pattern: '\\d', value: 251 },
  { name: '英文', pattern: '[a-zA-Z]{3,15}', value: 140 },
  { name: '符号“', pattern: '“+?(?=.)', value: 90 },
  { name: '符号”', pattern: '”+?(?=.)', value: 90 },
  { name: '符号（', pattern: '（+?(?=.)', value: 87 },
  { name: '符号）', pattern: '）+?(?=.)', value: 106 },
  { name: '符号(', pattern: '\\(+?(?=.)', value: 87 },
  { name: '符号)', pattern: '\\)+?(?=.)', value: 106 },
  { name: '符号.', pattern: '\\.+?(?=.)', value: -34 },
  { name: '符号，', pattern: '，+?(?=.)', value: 206 },
  { name: '符号、', pattern: '、+?(?=.)', value: 259 },
  { name: '符号!', pattern: '\\!+?(?=.)', value: 290 },
  { name: '符号?', pattern: '\\?+?(?=.)', value: 334 },
  { name: '符号？', pattern: '？+?(?=.)', value: 647 },
  { name: '符号;', pattern: ';+?(?=.)', value: 306 },
  { name: '符号。', pattern: '。+?(?=.)', value: 647 },
  { name: '符号！', pattern: '！+?(?=.)', value: 634 },
  { name: '符号 ', pattern: '\\s+?(?=.)', value: 206 },
  { name: '符号@', pattern: '@+?(?=.)', value: 368 },
  { name: '符号%', pattern: '%+?(?=.)', value: 709 },
  { name: '符号$', pattern: '\\$+?(?=.)', value: 465 },
  { name: '符号￥', pattern: '￥+?(?=.)', value: 643 },
  { name: '符号[', pattern: '\\[+?(?=.)', value: 215 },
  { name: '符号]', pattern: '\\]+?(?=.)', value: 197 },
  { name: '符号【', pattern: '【+?(?=.)', value: 162 },
  { name: '符号】', pattern: '】+?(?=.)', value: 131 },
  { name: '符号《', pattern: '《+?(?=.)', value: 134 },
  { name: '符号》', pattern: '》+?(?=.)', value: 50 },
  { name: '符号+', pattern: '\\++?(?=.)', value: 225 },
  { name: '符号-', pattern: '-+?(?=.)', value: 96 },
  { name: '符号……', pattern: '……+?(?=.)', value: 412 },
  { name: '符号:', pattern: ':+?(?=.)', value: 322 },
  { name: '符号：', pattern: '：+?(?=.)', value: 322 },
];
```

乐乐智能
1033ab6862a440feb5d3c1bb83db2e83
42427a39eb0641cc9e78ccb8721d1287

ray73pRs77uWwBSVQAh294oNkJhroX3Y

facc9b4e-bd4c-4e95-b707-4e8f8a5324a6

491f98ba-48bb-468e-909d-cf327394254d

线上客户问题处理
3dsdk 的调整
livekit 的联调和跟测

1033ab6862a440feb5d3c1bb83db2e83
a8f966d620f04d0eb34de64b15aa62eb

## 交互 sdk 和互动名片的 ASR 功能替换为统一的 ASRsdk

### 交互 sdk

#### 主要区别

1. 身份认证时，sdk 使用的是用户传入的 subkey；预览使用的是固定的 subkey，需要确认下这个 sdk 使用的具体是什么人的
2. 预览没有 costasr 接口的调用，即不会去计算扣减权益

### 互动名片

#### 瑞众的

zhangqinghua@ruiinsurance.com
ff39e3e4355a433b91b92dab1997d7f1
5756a67dde3f4a188b860b863c8944ef

1033ab6862a440feb5d3c1bb83db2e83
cb1986912bf744769422051d9457babe

给一个单次执行动作和表情的示例 ok
3dsdk 在手机上加载比较慢的问题
叮咚的声音
看下 threejs 官网配置和本地项目配置对比，是不是跟背景渲染有关

const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
// 立即停止流，只是为了获取权限
stream.getTracks().forEach(track => track.stop());

本周工作

- 交互 sdk，互动名片的跟测
- RTC2.0 上报日志完善
- 3dsdk 后台日志管理
- rtc2.0 客户问题的跟踪和解决，瑞众麦克风授权通知音问题的通过业务方式去规避
- 3dsdk 瑞幸客户问题跟踪解决，3d 模型效果调试

下周工作计划

- 瑞幸 3dsdk 接入持续跟进
- 更新 model_verify.html
- 调研 threejs 能不能优化毛发和光追效果
- rtc 的控制台日志优化，
- 交互 sdk 和名片的 ASR 的替换

## Three.js 与 Blender 渲染效果差异分析

1. **格式转换限制和渲染器限制**

工程文件到 threejs 效果这个环节的效果损失的调研结果如下：
效果损失的原因：

1. GLB 格式限制：GLB 格式不支持 Blender 原生渲染器的高级特性，如毛发系统、复杂的材质节点等，Blender 中的这些高级渲染特性在导出为 GLB 格式时会丢失；
2. Threejs 使用的是 WebGL 渲染器，没有光线追踪能力，追求性能而不是完全的物理精确性，与 Blender 的渲染器不同；

效果损失的补偿措施：

1. 可以在 Blender 中，将毛发，光追等特性烘培到法线贴图、环境光遮蔽贴图和光照贴图等，与 GLB 文件一起导出，前端通过应用贴图效果来模拟对应的特性；
2. threejs 官网没有找到与我们需求完全一致的示例，只有一个模拟光追效果的示例，使用的也是模型+贴图的实现方式
3. 加入贴图后，实际所需要下载的素材资源包也会增大，会影响模型的最终渲染出来的时间

- GLB/glTF 格式限制：GLB 格式不支持 Blender 的高级特性，如毛发系统、复杂的材质节点等，Blender 中的这些高级渲染特性在导出为 GLB 格式时会丢失；
- Threejs 使用的是 WebGL 渲染器，没有光线追踪能力，追求性能而不是完全的物理精确性，与 Blender 的渲染器不同

2. **通过烘培贴图进 glb 模型的方式去一定程度上弥补这种效果**

- 法线贴图---毛发效果
- 环境光遮蔽贴图
- 光照贴图

2. 渲染方式差异

- Blender: 使用光线追踪(Ray Tracing)或路径追踪(Path Tracing)渲染器，可产生物理精确的光照效果
- Three.js: 使用实时栅格化渲染，追求性能而非完全物理精确性

3. 着色器系统差异

- Blender 的 Cycles/EEVEE 渲染器支持复杂着色器网络
- Three.js 使用简化的 PBR 材质系统

### PBR（Physically Based Rendering，基于物理的渲染） 与 Blender 高级效果的差异

Three.js 的 PBR 材质与 Blender 中的材质系统存在差距，主要因为：

1. 渲染管线差异：

- Blender：可使用光线追踪或路径追踪，计算全局光照
- Three.js：使用实时光栅化，计算局部光照

2. 材质系统复杂度：

- Blender：支持复杂的材质节点网络和次表面散射
- Three.js：使用简化的 PBR 模型，优化为实时性能

3. 着色器能力：

- Blender：可创建高度自定义的材质行为
- Three.js：标准 PBR 着色器专为网页性能优化

> 这就是为什么 Blender 中的毛发、皮肤和其他复杂效果在导出到 glTF/GLB 格式后会丢失，因为这些高级效果在标准 PBR 材质模型中没有直接对应项。

1. 前端排查的数据给朱虹 ok
2. 3dsdk 加 sentry 上报 ok
3. sentry 上报的显示的时间格式不对 ok
4. RTC 上报加上 init 的 sessionId 或 requestId ok
5. 名片预览的接口报 500 为什么提示项目 id 错误: 项目 id 错误是在调用/api/v1/talk/project/get 接口的时候报的错: ok sdk 这边需要帮忙加个 client-type: PC 的请求头
6. 使用 threejs 渲染 glb，毛发问题可否修复
7. model_vefify.html 里面引用文件更新
8. 使用 fbxLoader 加载 fbx 文件 ok
9. 3dsdk 页面离开的时候调用 stop
10. 问下算法，request_id 和 session_id 传同样的值有没有问题
11. 3d 模型的动作执行时长问题，threejs 解析出的 glb 模型数据里面的确有每个动作的执行时长，不过工作台只有在预览的时候才会使用 threejs，前端可以在工作台的后台通过 threejs 去解析 glb 包，获取对应的动作信息，然后再根据动作名匹配上展示
12. 小程序的名片中明明已经播放音频了，还是展示提示播放媒体的按钮
13. 名片封面的静音按钮点击了没反应

本周工作

- 3dsdk 加载耗时问题排查+上报日志处理，添加生命周期配合客户业务需求，调研渲染损耗问题，fbx 格式模型渲染效果测试，页面离开自动调用 stop 接口，新增离线模式打包，更新建模使用的 verify_modify
- rtc2.0 控制台日志管理
- 交互 sdk 和互动名片跟测上线
- 线上客户问题对齐
  下周工作
- 3dsdk 模型预加载预研
- 3dsdk 瑞幸业务配合
- 交互 sdk 和易企聊线上问题处理
- RTC2.0 客户问题处理

18. 小程序能不能先加载包，然后再把文件传递到 webview 里面
19. 客户的 videodom 的高度不为偶数的问题，看看 get 接口返回的数据，先看 alpha 是不是 true，是的话看 videoSize 的值是多少，不是的话看 attribute 里面的值

### 这个项目 id 和 taskid 一句话说了一大半突然就不说了，看见音频流又重新订阅了一次，由 2 个音频轨道变成了 3 个音频轨道，(还有就是为什么原先就会有 2 个音频轨道？)

ad8c084f9aa740f1ad63ef3d1bfd2d85_d0546365010341509db801103eb27440

### 名片静音按钮不能用的问题

rtc-init-contanire 的 z-index 改成 21

现在是流式文本的第一部分，动作是 hello 和 no，无限循环，没有表情。现在是第二部分，没有动作，表情是 happy。

xiaoiceRTC_2.0.1_Beta1
/[a-2A-20-9\\x{0430}-\\x{844F}\\x{8410}-\\x{042F}-]/g

for (const item of textSpeakTimeMap) {
try {
const regex = new RegExp(item.pattern, 'g');
const matches = remainingText.match(regex);

        if (matches) {
          // 累加匹配到的模式的时间
          totalTime += matches.length * item.value;

          // 从剩余文本中移除已匹配的内容
          remainingText = remainingText.replace(regex, '');
        }
      }catch(e: any){
        console.warn('........rtc 正则表达式有误', e);
        continue
      }
    }



    https://aibeings-vip.xiaoice.com/CRTCPreview/3779193f0f9b4f74afd2121617ab4252



    75a1b2b7683c4d95a402ad270464cb81
    7b4bd7e5a6434139b09fb2f943c705ed

748743a0971a4515a11e29cc32fc41f3
a2d27e567fca4eab901abcc373eb5f0f

c96b37589e3349958e6afa3eb3d18d85
ad8c084f9aa740f1ad63ef3d1bfd2d85 69a0f12671d94768af0ebf8e91240f8b

1. livekit minimax isFirst 的问题: ok
2. 3dsdk： 小程序里面 h5-h5 缓存的验证: 彭舟
3. 3dsdk： 配置一个方法作为总入口，分 3 条路去处理
4. 3dsdk： 说话口型问题: ok
5. 3dsdk: json 配置增加颜色材质的配置，并在代码里面处理

你好，我是小小，你今天心情怎么样呢

这条数据在第一次 talk 完的时候新增了一条音频流，后面第二次 talk 的时候，就说了第一句人物就卡住了，但是音频没有卡住，最后音频式完整说完了，但是 onTalkStart 只返回了第一句话的结果
cb1986912bf744769422051d9457babe_7079c8be78ac4a64ba37ecf33028001e

另一个： cb1986912bf744769422051d9457babe_cbeda71fab314df6bd2ac2c209317362 卡住时间 7:22:10

另一个： cb1986912bf744769422051d9457babe_8e15bf948aac49b0a68b645dd8c24a8d
8: 08: 30

ff896c8845004083a56fd39a02f305d3

```xml
<action name="['sikao', 'dazhaohu']" loop=-1>我现在在说第一部分的第一句话，第一部分的动作是 思考 和 打招呼，无限循环，第一句话没有表情，<emotion name="smilejawOpen">现在是第一部分的第二句话，第二句的表情是 咧嘴笑。</emotion></action><action name="["jieshao", "kun"]" loop=1><emotion name="sleep">现在是第二部分，动作是介绍和困，循环一次，表情是 sleep。</emotion></action>
```

```xml
<action name="['sikao', 'dazhaohu']" loop=2><emotion name="smilejawOpen" duration=2000></emotion><emotion name="enjoy" duration=4000></emotion></action>
```

```xml
<action name="['dazhaohu','fahongbao', 'idle', 'jieshao', 'kaixintiaoyue', 'kun', 'manzu', 'sikao', 'xiangshoukafei']" loop=-1></action>
```

```xml
<action name="['fahongbao', 'xiangshoukafei']" loop=-1>我现在在说第一部分的第一句话，第一部分的动作是 发红包 和 享受咖啡，无限循环，第一句话没有表情，<emotion name="think">现在是第一部分的第二句话，第二句的表情是 think。</emotion></action><action name="["kun"]" loop=1><emotion name="mouthSmileLeft">现在是第二部分，动作是困，循环一次，表情是 mouthSmileLeft。</emotion></action>

```

```xml
<action name="['kun']" loop=1><emotion name="sleep" duration=3533></emotion></action>
<action name="['jieshao']" loop=1><emotion name="smilejawOpen" duration=2700></emotion></action>
<action name="['dazhaohu']" loop=1><emotion name="smilejawOpen" duration=2200></emotion></action>
<action name="['fahongbao']" loop=1><emotion name="mouthSmileLeft" duration=3533></emotion></action>
<action name="['kaixintiaoyue']" loop=1><emotion name="smilejawOpen" duration=2533></emotion></action>
<action name="['manzu']" loop=1><emotion name="enjoy" duration=5400></emotion></action>
<action name="['sikao']" loop=1><emotion name="think" duration=3900></emotion></action>
<action name="['xiangshoukafei']" loop=1><emotion name="enjoyCoffee" duration=5566></emotion></action>
<action name="['idle']" loop=1></action>

<action name="['dazhaohu']" loop=1>您好，luckin coffee瑞幸咖啡全球品牌代言人是易烊千玺；luckin coffee瑞幸咖啡全球品牌代言人及茶饮首席推荐官是刘亦菲。感谢您对瑞幸咖啡的关注与支持。</action>
<action name="['jieshao']" loop=1>瑞幸的基底乳不是用植脂末做的哦~不过你还没有明确要选择的商品呢，所以暂时没办法给你展示商品可选属性信息啦。可以告诉我你想点的商品，这样我就能帮你选商品并展示属性咯。瑞幸的茶包和茶粉品质都是有保障哒，不会有添加剂超标问题哦~不过目前你没有明确要选择的商品呢，暂时没办法为你提供商品属性信息啦。你可以告诉我你想选的具体商品，我来帮你看看它的可选属性哟。</action>
<action name="['kun']" loop=1>修狗贴纸来啦，已为你加购。贴纸不是饮品哦~修狗贴纸很可爱哒！好嘞～ 请选择想要切换的门店</action>
<action name="['fahongbao']" loop=1><emotion name="mouthSmileLeft" duration=3533>不好意思，没有瑰夏拿铁哦~ 试试IIAC金奖豆的热丝绒拿铁不加糖。⁠为你点了热的少少甜无奶油蛇来运转红枣拿铁。褚橙拿铁是一款有独特风味的饮品哦~它经过1800 + 小时日晒，造就黄金酸甜比。这款饮品有多种可选属性，例如： 温度有冰、热。 糖度有少少甜、标准甜、少甜</emotion></action>
<action name="['kaixintiaoyue']" loop=1>好哒，已为你加购半熟芝士蛋糕。好哒，一杯冰的不加糖小黄油拿铁。</action>
<action name="['manzu']" loop=1><emotion name="enjoy" duration=5400>我们将不满18周岁的自然人视为未成年人。我们的产品和服务主要面向成年人。如果没有父母或监护人的同意，未成年人不应创建自己的瑞幸平台账号。已经创建账号的，我们推定您是具有相应的民事行为能力的成年人。</emotion></action>
<action name="['sikao']" loop=1><emotion name="think" duration=3900>冰美式有多种可选属性，例如： 咖啡豆：日晒花魁豆。杯型：12oz中杯、16oz大杯、20oz超大杯。景区附近瑞幸门店信息我还不知道呢，不过有小黄油扁扁可颂，要不要来一个？</emotion></action>
<action name="['xiangshoukafei', 'fahongbao']" loop=1><emotion name="enjoyCoffee">您好，刘亦菲是luckin coffee瑞幸咖啡全球品牌代言人及茶饮首席推荐官，代言瑞幸咖啡品牌全线饮品。感谢您对瑞幸咖啡的关注与支持。</emotion></action>
<action name="['idle']" loop=1>Lucky有很多优惠活动，具体请以官方网站为主哦。哎呀呀，Lucky 还没有发现你的购物车里面有要下单的商品呢。Lucky暂时答不了这个问题哦～</action>
```

```xml
<emotion name="smilejawOpen" duration=4000></emotion>
<emotion name="enjoy" duration=4000></emotion>
<emotion name="enjoyCoffee" duration=2000></emotion>
<emotion name="mouthSmileLeft" duration=2000></emotion>
<emotion name="sleep" duration=2000></emotion>
<emotion name="think" duration=2000></emotion>
```

kaixintiaoyue
fahongbao
manzu
xiangshoukafei

17:32:04

1. 初始检查：检查输入文本是否为空
2. 标签识别：通过 hasActionOrEmotionTags 判断是否包含 action 或 emotion 标签
3. 无标签处理路径：

- 有 sessionId：按照流式文本处理（driveStreamTalkFn）
- 无 sessionId：按照长文本处理（handleDriveLongTextTalk）

4. 有标签处理路径：

- 先通过 isEmptyTags 判断是否为空标签文本（即只有标签，没有其他普通文本内容）
- 空标签文本：直接调用 playActionEmotion 播放对应的动作和表情
- 非空标签文本：
  - 有 sessionId：调用 driveTalkEmotionActionStreamFn 处理带标签的流式文本
  - 无 sessionId：调用 driveTalkEmotionAction 处理带标签的非流式文本

5. 错误处理：全程使用 try-catch 包裹，捕获异常并通过 onError 报告

1. 3dsdk 的流程图处理
1. 3dsdk 关闭页面断开的时间是多久需要确认
1. livekit 加 text 帧的信息处理来补全字幕

1 分半到 3 分钟

591762c9d1b04dfd93d8c0f48e8e0296
327d3b4d27fa40c784a59ba8527b6b6a

- 瑞幸 3d 模型的调试与适配，动作，表情，json 配置，与下载问题调研
- 3dsdk 统一驱动接口 的开发： 这个多测一下
- rtc2.0 支持火山 tts
- rtc2.0 音频与视频卡顿的问题排查
- rtc2.0 历史遗留问题的优化
-
- 3d 模型完整全套动作的适配调试
- rtc2.0 支持火山 tts 功能上线
- 3dsdk 统一驱动接口部署正式环境

监听到 LLM_RESPONSE, 触发 updateOrCreate -》 然后触发之前调用 getNewAnswer 方法的时候，通过 dialog.subscribeText 方法添加的订阅方法 onSubscribe

cb1986912bf744769422051d9457babe prod 这个项目 id 非常容易复现音频是视频同时卡顿的问题

752ff60f6c41419191c90b42ae5aa155 RoomName_ffaca0dd41824aa0badd21fcd11a810c 字幕全了，语音不全

taskId: f5df47d628e94ef1b8dcccbd95143635
roomId: RoomName_f5df47d628e94ef1b8dcccbd95143635
这个项目如果使用了预设的问答，一定会卡

56576adf20004a9d8757e9746e5e8b55_aa285675218c4a1fb52190e8b0c5b410
1：42：48 发生卡顿，有 rpc 调用失败的记录
RoomName_aa285675218c4a1fb52190e8b0c5b410

2 个表情执行覆盖的时候 wait 的时间有问题
改配置兼容视锥体
改代码兼容视锥体

你的梦想是什么
你未来有什么打算
你擅长什么
你是谁

风穿过解冻的河流，在岸边柳梢上系了个蝴蝶结。清晨的阳光碎成金箔，落在青石板路上，像撒了一把未拆封的星星。我踩着露水出门，看见蒲公英举着小伞在草坪上散步，玉兰树踮起脚尖，把花苞开成了天边的云朵。​ 街角的咖啡店飘出焦糖香气，和着樱花的甜腻在空气里发酵。穿风衣的姑娘蹲下身，给流浪猫递了块三文鱼罐头，橘色的绒毛在阳光下泛起琥珀色的光。胡同口的老槐树正簌簌落着白花，卖槐花蜜的老人掀开木盖，清甜的气息便漫过整条街巷，勾得自行车铃铛都变得轻快。

2c1c15b963a14800b6a65ff243eaa506
8e35f0c6d5214c789154777a74c7fcc6

本周工作

- 3dsdk 综合接口及模型动作道具支持功能上线
- 3dsdk 在客户的 app 里面会导致 webview 崩溃问题处理
- 3dsdk 完善上报日志，优化打包机制
- 3dsdk 支持初始化静音，中途切换静音
- livekit 卡顿问题跟踪
- 线上客户问题支持
- 周末跟项目经理还有建模一起确认瑞幸最终模型效果
  下周工作
- RTC2.0 支持火山 TTS 功能上线
- 瑞幸 3d 业务上线支持
- 员工平台 3d 模型预览页面替换为 3dsdk

1. 捋一下 LLM_RESPONSE 里面都有哪些数据是使用到的

```js
sentry?.report?.warning({
          module: EReportModule.EmployeeAttributes,
          keyword: '虚拟人预设的声音不在声音列表中',
          extra: {
            // 选择的虚拟人id
            personaBizId: bizId,
            // 返回的预设的声音
            defaultVoice,
            // 声音列表
            allVoiceListLength: this.allVoiceList.length
          }
        })
 sentry.report?.error(
            {
              module: EReportModule.Rtc,
              keyword: 'websorcket连接失败原因不明'
            },
            info
          )
Sentry.captureException(newError, {
    level: level as Sentry.Severity,
    tags: {
      module
    },
    extra
  })
```

45f7061f6f3c439eb7d5d803e99c39621e62c73adb694c83a3d3ca73950986bf

xiaoiceThreeDimensionSDK1.0.1_Beta1

filename: "xiaoiceThreeDimensionSDK1.0.1.js", //决定 bundle 输出名称
urlPrefix: '~/interaction/public/js/sdk/release/'

1. 3dsdk 打包的优化处理，3dsdk 预览的预研
1. 3dsdk 支持初始化静音，中途切换静音
1. rtcsdk 打包优化，区分正式版本和 beta 版本
1. 周末跟项目经理还有建模一起确认最终模型效果
   账号： 16620498895
   项目 ID： ffe72b8128c64060b46faa54da633ad1

18: 36: 28

16:25:27

17:11:50

0：15：20 项目 id cb1986912bf744769422051d9457babe RoomName_db4bc5a6fcd6409f8aaa987dc43b155e
0：23：00 项目 id cb1986912bf744769422051d9457babe RoomName_c9ba16ad408744e29e360705a9996b82
01：15：10 项目 id cb1986912bf744769422051d9457babe RoomName_1b198602e1664253ad836d717f28c32d
06：14：02 项目 id cb1986912bf744769422051d9457babe RoomName_6861cb611ea0485c9d8d2993806d5c73

RoomName_cc8608ef1e3d4d45b2e9fbe2f937ce3f

- 确认下交互 sdk 的推荐问题列表这个业务是否还存在？
- replyText 是否可以直接使用 plainText 替代
- 是否应该使用一个新的生命周期钩子来区分 llm 和 text 的流数据，比如：onLLMStreamData
- 卡顿每次都会伴随多出一条音频流，可以根据做这个上报
- sdk 是否可以先上一个 beta 版本给客户体验，然后再上正式版
- 首帧，耗时 时间累加了，需要处理下

- 80%情况控制首帧在 800ms 以下，需要处理得隐藏一点

```js
const originData = {
  from: {}, // 未使用, 响应来源信息，包含音频流，视频流等信息
  topic: 'llm_response', // 使用
  // 使用，原始数据为ArrayBuffer格式
  payload: {
    session_id: '', // 使用
    // 使用，原始数据为string格式的json字符串
    response: {
      code: 200, // 使用
      message: null, // 使用
      logTraceId: 'cf643f061301246b', // 未使用
      replyText: '', // 未使用，响应的文字片段
      // 使用，文本，素材等数据，目前会作为originalAnswer返回给用户
      fatReply: {
        replyText: '', // 使用，回复的数据，但如果是开场白的话，这里面会包含素材数据
        plainText: '', // 暂未使用，如果是开场白的话，里面只有纯文本，没有素材，是否可以切换成这个数据
        extra: {}, // 使用，自定义信息
        payloads: {
          canvas: '', // 使用，会话相关的素材
        },
      },
    },
  },
};
```

xiaoiceRTC_2.0.1_Beta1.js
xiaoiceRTC2.0.1.js

固定回复的话重复了 2 次
RoomName_f298335957d740d58c722f3073b78ff5
sessionId: 30551340-43e9-4d12-815e-715dfd4f1e75

15:03:40
RoomName_68c5c0575df54016a286e7b46d69a26f 有一两秒有一点点卡顿

15:22:34
RoomName_ab73e6d90a3645f3bf7e193f42a8e3fa
17:15:28
RoomName_82d7f787f79f48d992e96a33b7ba812a

一直没有触发 Last_frame
RoomName_fddcf04aaf16453fb220803780005302
已为您查到"2""0""1""6""1""3""9""4""3""5""3""7""4""0""8""8"的保单
"2""0""1""6""1""3""9""4""3""5""3""7""4""0""8""8"

1. 打包出来的包是设置一个区别与正式版的单独包名放到 oss 吗，客户会不会去对比这个包名与文档的包名不一致？
2. 客户会实际去看代码吗？如果客户看代码的话会看到点击开始 talk 的处理方法，以及 onTalkStart 的回调，客户会不会由此自己在这 2 个地方去写代码去计算时间，然后和我们实际得出的时间对比？（可以在 demo 里面直接把 onTalkStart 这个回调删除了，但是不排除客户可能会先去看文档了解这个信息）
3. 开场白的首帧耗时是不是不要返回，这个是走的 ask 逻辑，时间肯定超过 900ms
4. 所有上报逻辑是否可以都删除了？

5. 今天调试过程还是发现了卡顿的问题，使用的是小冰的 TTS，谢朕的反馈是跟之前一样， agent 出现了 CPU 慢的报警，触发重连

RoomName_531c9e0c6869401ba541ed59f1ac8879
14:50:40

// useEffect(() => {
// const handleVisibilityChange = () => {
// if (document.hidden) {
// // 页面隐藏时暂停播放
// glbRef.current?.getCharacter()?.breakTalk();
// } else {
// // 页面重新可见时恢复音频上下文
// if (glbRef.current?.getCharacter()?.audioContext) {
// // 确保 Howl 实例存在时恢复它
// glbRef.current.getCharacter().audioContext.play();
// }
// // 同时恢复 Howler.js 全局上下文
// if (window.Howler) {
// window.Howler.ctx && window.Howler.ctx.resume();
// }
// }
// };

// document.addEventListener('visibilitychange', handleVisibilityChange);
// return () => {
// document.removeEventListener('visibilitychange', handleVisibilityChange);
// };
// }, []);

1. 页面显隐暂停播放 ok
2. 首帧张手要隐藏 ok
3. 交互 sdk 预览图使用 preview 的那一张，然后看看交互 sdk 和互动名片，如果接口报错了，不刷新页面直接再点启动，是不是就不请求接口了 ok
4. 发布火山到线上 ok
5. rtc 的上报处理：包括 rpc 调用失败报错，多生成了轨道的报错

最后的口型，oninteractionstart，每次页面展示就播放: ok

> 要看下如果中途有暂停的话，播放完的时候是不是嘴巴的嘴型会不会复原成常态: ok

1. roomId 放在初始化完成之后的回调里给客户 ok
2. RTC2.0 错误的处理，在 onError 的时候把 roomName 也放在回调的参数里面
3. 全局的报错，如控制台里抛出的报错也要使用 onError 响应返回，这里要处理下交互 sdk 和易企聊，易企聊一触发 onError 就会做断开处理，而且小程序端易企聊挂断的时候一定会触发一个接口 400 的错误，需要看下是什么原因
4. rtc 的上报处理：包括 rpc 调用失败报错，多生成了轨道的报错
5. sentry 上报处理，一个是捕获全局的错误，另一个是错误的处理需要处理好 issue，同时
6. sentry 里面加入警报，然后配合企微的机器人通知使用
7. 更新版本后要在群公告里面通知大家
8. 给所有的 onError 调用添加一个 level 的选项，用户可以根据这个值来判断是否需要调用 stop 断开房间连接

方案： 初始化 debug，同时在 debug 里面初始化 sentry, 传入 onError，projectId。。。。。在更新了 roomName 的时候配置 debug 的 config，传入 roomName、agentId 和 taskId，userId。。。。。在 forceError 这个 api 里面直接上报错误和调用 onError。。。。在 onError 里面加个标识，用于给使用方判断是否需要调用 stop 断开房间连接

```js
debug.forceError({
  log: ['错误信息1', '错误信息2'],
  onErrorInfo: {
    code: 10001,
    message: '错误信息1',
  },
  report: {
    module: 'moduleName',
    text: '错误信息1'
    error: new Error('错误信息1'),
  },
});
```

本周工作

- 火山 TTS 支持上线
- 3dsdk 的页面隐藏暂停播放 和 初始模型展示优化，瑞幸 3dsdk 项目上线
- rtc 浏览器控制台日志位置指向优化
- rtc 错误日志处理，onError，上报，sourcemap，日志告警
- asr 单例模式优化
- 交互 sdk 预览展示图片优化
- int 特殊数字人监听流失败的问题
  下周工作计划
- 瑞幸的预加载逻辑
- rtcsdk2.0 的错误上报处理
- 百变数字人需求评审与开发
  6cd95602ac4f45218f0519b9dcd4371d_2025-09-22_11:54:05
  6cd95602ac4f45218f0519b9dcd4371d_2025-09-22_11:58:05

preload=1

1. 瑞幸的预加载逻辑
2. 交互 sdk 的开场白保存的逻辑
3. rtc 的告警

const \_mode = state.speakMode === speakModeEnum.QUIET ? speakModeEnum.NOISY : speakModeEnum.QUIET
handle.switchSpeakMode(\_mode)

{
"buttons": [
{
"name": "按钮名称",
"action": "command",
"text": "快捷指令文本"
},
{
"name": "按钮名称",
"action": "link",
"url": "https://example.com"
}
],
"link": {
"url": "https://www.baidu.com",
"title": "新华保险提示您，快点续费"
}
}

```js
{
  "buttons": [
    {
      "name": "A意外住院医疗理赔需要的材料",
      "action": "command",
      "text": "意外住院医疗理赔需要的材料"
    },
    {
      "name": "B疾病住院医疗理赔需要的材料",
      "action": "command",
      "text": "疾病住院医疗理赔需要的材料"
    }
  ]
}

```

MTc1MzIwMzc2NjI0Mg==

1. 按钮样式
2. 下面语音条的键盘 icon 的样式

3. 微信环境下的视频播放
4. 浏览器的样式适配
5. 视频和图片的层级不够高
   xiaoiceASR1.0.9

本周工作

- 瑞幸的预加载逻辑
- 新华保险招标项目开发
- 丹霞山和建信消金 3dsdk 项目对接
- sdk 线上客户问题处理
- rtcsdk2.0 的错误上报处理
  下周工作计划
- rtc 卡顿问题联调

int 环境卡顿，出现 4 个流
RoomName_6aba3f31c2bc456ba1f34376b593dbc6
11: 31:00

阿里云的音频说不了开场白
固定问答出现速度慢
数字人从静态图片切换到视频流会闪一下

1. 支持点击封面视频切换项目
2. 支持打开摄像头并展示摄像头内容
3. 支持切换数字人分辨率
4. 支持数字人全屏，半屏和悬浮模式切换展示
5. 支持键盘输入的交互模式
6. 支持底部常用功能
7. 支持弹窗显示更多功能
8. 支持字幕的显隐，字体大小，显示区域大小配置
9. 字幕支持配置按钮（支持发送对话或跳转链接），链接小弹窗，开启摄像头功能
10. 支持使用弹窗在当前页面跳转链接
11. 不同悬浮模式的样式适配
12. 不同会话模式的样式适配
13. 支持自动关闭推荐会话弹窗
14. 会话的视频，图片和视频支持手动关闭

15. 先在 prod 上测试，可以的话再在 int 上测试
16. 先 ontalkstart 之后 500ms 之后立马问下一个问题，如果不行就说 2000ms
17. 如果不行的话，就初始化，说 2 轮对话，然后 stop，然后再初始化，再说 2 轮对话，这样重复

18. 每隔 20 秒请求结束语的问题
19. 推荐问题的素材不展示

RoomName_3e645e3c8c334d5ca3f49aa0edb59161 int 环境，一直循环 ask 说话，突然卡住不动了，打断之后再继续 ask 或 say，数字人能动，但不说话了，看日志是一个关键帧的请求（pliCount = 1）
